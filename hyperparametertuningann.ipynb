{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1-2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"Exited\", axis=1)\n",
    "y = df[\"Exited\"]\n",
    "\n",
    "# Define feature types\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.difference(categorical_features)\n",
    "\n",
    "# Create preprocessor\n",
    "# Set OneHotEncoder output to dense (sparse=False) to avoid sparse matrix issues with Keras\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit preprocessor and get number of features after transformation\n",
    "preprocessor.fit(X_train)\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "n_features = X_train_transformed.shape[1]\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Features after preprocessing: {n_features}\")\n",
    "\n",
    "# Define model builder using n_features from outer scope\n",
    "def build_model(neurons=32, layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(n_features,)))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model with scikeras KerasClassifier\n",
    "model = KerasClassifier(\n",
    "    model=build_model,\n",
    "    verbose=0,\n",
    "    # fix for warning about y needing integer labels - your y is already binary 0/1 so no LabelEncoder needed\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__model__neurons': [32, 64],\n",
    "    'classifier__model__layers': [1, 2],\n",
    "    'classifier__epochs': [10, 20],\n",
    "    'classifier__batch_size': [32]\n",
    "}\n",
    "\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=1, n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "print(\"Best Params: \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"First 10 predictions: {y_pred[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Deep Learning)",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
